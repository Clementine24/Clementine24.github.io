<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Introduction深度学习三步骤：定义网络、损失函数、优化">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning: Introduction">
<meta property="og:url" content="http://example.com/2022/02/08/Deep-Learning-Introduction/index.html">
<meta property="og:site_name" content="Clementine&#39;s blog">
<meta property="og:description" content="Introduction深度学习三步骤：定义网络、损失函数、优化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/卷积层结构.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/汇聚层结构.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/卷积网络结构.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/空洞卷积.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/微步卷积.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/残差网络.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/延时神经网络.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/非线性自回归.png">
<meta property="og:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/循环神经网络.png">
<meta property="article:published_time" content="2022-02-08T09:13:32.000Z">
<meta property="article:modified_time" content="2022-02-17T13:51:36.115Z">
<meta property="article:author" content="Yifan Li">
<meta property="article:tag" content="deep learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/02/08/Deep-Learning-Introduction/卷积层结构.png">

<link rel="canonical" href="http://example.com/2022/02/08/Deep-Learning-Introduction/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Deep Learning: Introduction | Clementine's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Clementine's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/02/08/Deep-Learning-Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yifan Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Clementine's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Deep Learning: Introduction
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-08 17:13:32" itemprop="dateCreated datePublished" datetime="2022-02-08T17:13:32+08:00">2022-02-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-02-17 21:51:36" itemprop="dateModified" datetime="2022-02-17T21:51:36+08:00">2022-02-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>深度学习三步骤：定义网络、损失函数、优化</p>
<span id="more"></span>
<h2 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h2><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>全连接层</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>全连接的前馈神经网络参数较多，需要较多样本学习；且很难提取局部不变性特征（过拟合）。</p>
<p>引入卷积神经网络，也是一种前馈神经网络，结构特性：局部连接、权重共享、空间或时间上的次采样</p>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>常用于计算信号的延迟积累</p>
<p>时刻t收到的信号$y_t$（卷积输出）为当前时刻产生的信息和以前时刻延迟的信息（输入信号序列）叠加：</p>
<script type="math/tex; mode=display">
y_t=\sum_{k=1}^Kw_kx_{t-k+1}</script><p>$w_k$称为滤波器或卷积核。</p>
<p>假设input信号序列长度为N，卷积核长度为K，则输出卷积信号长度为N-K+1.</p>
<h3 id="卷积作用"><a href="#卷积作用" class="headerlink" title="卷积作用"></a>卷积作用</h3><ul>
<li>近似微分：例：$[-\frac{1}{2},0,\frac{1}{2}]$近似一阶；$[1,-2,1]$近似二阶</li>
<li>低通滤波/高通滤波：例：$w=[\frac{1}{3},\frac{1}{3},\frac{1}{3}]$检测信号序列中的低频信息（变换缓慢，如均值）；$w=[1,-2,1]$检测信号序列中的高频信息（变化较快，如二阶导）</li>
</ul>
<h3 id="卷积扩展"><a href="#卷积扩展" class="headerlink" title="卷积扩展"></a>卷积扩展</h3><ul>
<li>滑动步长S：增加步长减少信号输出长度</li>
<li>零填充P：往信号输入两端补充P个0</li>
</ul>
<p>根据卷积结果长度可以分为三类：</p>
<ul>
<li>窄卷积：S=1，P=0.输出长度为M-K+1  <font color="green">早期文献默认</font></li>
<li>宽卷积：S=1，P=K-1.输出长度为M+K-1</li>
<li>等宽卷积：S=1，P=(K-1)/2.输出长度为M  <font color="green">目前文献默认</font></li>
</ul>
<h3 id="二维卷积"><a href="#二维卷积" class="headerlink" title="二维卷积"></a>二维卷积</h3><p>应用于图像处理等二维矩阵形式信息序列</p>
<p>定义一个输入信息$X$和滤波器$W$的二维卷积为$Y=W*X$，其中</p>
<script type="math/tex; mode=display">
y_{ij}=\sum_{u=1}^U\sum_{v=1}^Vw_{uv}x_{i-u+1,j-v+1}</script><p>同样有步长S和零填充P供选择。</p>
<p>作用：作为特征提取器</p>
<p>应用到神经网络中，希望自动学习这个卷积核$W$，用以提取特征。</p>
<h3 id="神经网络-1"><a href="#神经网络-1" class="headerlink" title="神经网络"></a>神经网络</h3><p>用卷积层代替全连接层。</p>
<p>参数数量大大降低，只有卷积核数量个。</p>
<h4 id="互相关"><a href="#互相关" class="headerlink" title="互相关"></a>互相关</h4><p>计算卷积需要进行卷积核翻转，比较麻烦，但我们的目的其实是提取特征，因此翻转是不必要的。修改为互相关形式：</p>
<script type="math/tex; mode=display">
y_{ij}=\sum_{u=1}^U\sum_{v=1}^Vw_{ij}x_{i+u-1,j+v-1}</script><p>之后除非特别说明，一般都为互相关。</p>
<h4 id="多个卷积核"><a href="#多个卷积核" class="headerlink" title="多个卷积核"></a>多个卷积核</h4><p>使用多个卷积核，得到多个特征映射(depth)，并将其拼接起来作为输出。</p>
<p>例如某卷积层：</p>
<ul>
<li>输入：D个特征映射$M\times N\times D$</li>
<li>输出：P个特征映射$M’\times N’\times P$</li>
</ul>
<h4 id="卷积层的映射关系"><a href="#卷积层的映射关系" class="headerlink" title="卷积层的映射关系"></a>卷积层的映射关系</h4><script type="math/tex; mode=display">
Z^P=W^P\otimes X+b^P=\sum_{d=1}^DW^{P,d}\otimes X^d+b^P,\\
Y^P=f(Z^P)</script><p>可以将P个输出的特征映射看为输入的D个特征映射的<strong><em>全连接</em></strong>！</p>
<p>卷积层结构：</p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/卷积层结构.png" alt="卷积层结构"></p>
<h4 id="池化层（汇聚层）"><a href="#池化层（汇聚层）" class="headerlink" title="池化层（汇聚层）"></a>池化层（汇聚层）</h4><p>卷积层可以显著减少连接个数（前馈神经网络是每一个输入信号有一个单独权重，得到总加权和，卷积神经网络是只有少数权重滑动加权，得到多个加权和），但是每个特征映射的神经元个数并没有显著减少（M-K+1）。</p>
<p>因此使用汇聚，将大的特征映射划分为几个小的特征映射，从每个小块中提取出一个代表元素。如：最大汇聚、平均汇聚、max-in-time(取每个depth最大的元素，好处是控制输出维数，只和卷积核的数量相关）。</p>
<font color="green">可以看做特殊的卷积层</font>

<p>池化层结构：</p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/汇聚层结构.png" alt="池化层结构"></p>
<h4 id="卷积网络结构"><a href="#卷积网络结构" class="headerlink" title="卷积网络结构"></a>卷积网络结构</h4><p><img src="/2022/02/08/Deep-Learning-Introduction/卷积网络结构.png" alt="卷积网络结构"></p>
<h3 id="其他卷积网络"><a href="#其他卷积网络" class="headerlink" title="其他卷积网络"></a>其他卷积网络</h3><h4 id="空洞卷积"><a href="#空洞卷积" class="headerlink" title="空洞卷积"></a>空洞卷积</h4><p>增加输出单元的感受野的方法：</p>
<ul>
<li>增加卷积核的大小</li>
<li>增加层数</li>
<li>在卷积之前进行汇聚操作（但会丢失部分信息）</li>
<li><strong>空洞卷积</strong>：通过给卷积增加“空洞”来变相地增加其大小</li>
</ul>
<p><img src="/2022/02/08/Deep-Learning-Introduction/空洞卷积.png" alt="空洞卷积"></p>
<h4 id="转置卷积-微步卷积"><a href="#转置卷积-微步卷积" class="headerlink" title="转置卷积/微步卷积"></a>转置卷积/微步卷积</h4><p>一般的卷积是高维映射为低维，该卷积将低维特征映射到高维特征。</p>
<p>思想就是将步长S调为小于1的值，方法为在元素之间以及矩阵周围插入适量的空格。</p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/微步卷积.png" alt="微步卷积"></p>
<h4 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h4><p>问题：在深度网络中，使用一个非线性单元去逼近目标函数，会发现当目标函数为线性函数时，效果非常差。</p>
<p>解决方法：将目标函数拆分为两部分：恒等函数和禅茶函数：</p>
<script type="math/tex; mode=display">
h(x)=\underbrace{x}_{恒等函数}+\underbrace{(h(x)-x)}_{残差函数}</script><p>给非线性的卷积层（$h(x)-x$）添加直连边(shortcut connection)的方式来提高信息的传播效率。</p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/残差网络.png" alt="残差网络"></p>
<p>好处：当卷积函数的导数比较小时，加了一个x相当于加了偏置1，使得不会出现链式法则梯度消失的情况。</p>
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>不同于前两种，该网络信息可以反向传递。</p>
<p>当信号序列与时间相关时，有时候t时刻的输出不仅和t时刻的输入相关，还会和前面时间的输入、输出相关，但在前馈网络中，假设每次输入都是独立的，也即每次网络的输出只依赖于当前的输入。<strong>如何给网络增加记忆能力，处理任意长度的时序数据？</strong>：</p>
<h3 id="时延神经网络"><a href="#时延神经网络" class="headerlink" title="时延神经网络"></a>时延神经网络</h3><p>建立额外的延时单元，用以储存网络的历史信息（输入、输出、隐状态……）</p>
<script type="math/tex; mode=display">
h_t^{(l)}=f(h_{t}^{l-1},h_{t-1}^{l-1},\cdots,h_{t-K}^{l-1})</script><p><img src="/2022/02/08/Deep-Learning-Introduction/延时神经网络.png" alt="延时神经网络"></p>
<h3 id="有外部输入的非线性自回归模型"><a href="#有外部输入的非线性自回归模型" class="headerlink" title="有外部输入的非线性自回归模型"></a>有外部输入的非线性自回归模型</h3><p>自回归模型的加强版</p>
<p><strong>自回归模型</strong>：一类时间序列模型，$y_t=w_0+\sum_{k=1}^Kw_ky_{t-k}+\epsilon_t$，其中$\epsilon_t\sim N(0,\sigma^2)$为噪声</p>
<p>有外部输入的非线性自回归模型：</p>
<script type="math/tex; mode=display">
y_t=f(x_t,x_{t-1},\cdots x_{t-K_x},y_{t-1},y_{t-2},\cdots,y_{t-K_y})</script><p>其中$f(\cdot)$是一个非线性函数 <font color="green">可以是前馈神经网络</font></p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/非线性自回归.png" alt="非线性自回归"></p>
<h3 id="循环神经网络-1"><a href="#循环神经网络-1" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><p>使用带自反馈的神经元：$h_t=f(h_{t-1},x_t)$</p>
<p><img src="/2022/02/08/Deep-Learning-Introduction/循环神经网络.png" alt="循环神经网络"></p>
<h4 id="简单循环网络（SRN）"><a href="#简单循环网络（SRN）" class="headerlink" title="简单循环网络（SRN）"></a>简单循环网络（SRN）</h4><script type="math/tex; mode=display">
h_t=f(Uh_{t-1}+Wx_t+b)</script><p>由<strong>循环神经网络的通用近似定理</strong>可知，一个完全连接的循环网络是任何非线性动力系统的近似器。</p>
<p><strong>图灵完备</strong>：所有的图灵机都可以被一个由使用Sigmoid型激活函数的神经元构成的全连接循环网络来进行模拟。</p>
<p>根据图灵完备，一个完全连接的循环神经网络可以近似解决所有可计算问题。</p>
<h4 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h4><p>以SRN为例，记$L=\sum_{i=1}^TL_t$为损失函数，则有</p>
<script type="math/tex; mode=display">
z_t=Uh_{t-1}+Wx_{t}+b\\
h_t=f(z_t)</script><p>根据以上两条公式，可推得（注意，基于寻欢神经网络的特性，$z_t$不止和$h_{t-1}$有关，事实上，是和所有$t-1$之前的$h$有关，求导时要注意）：</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial U}=\sum_{t=1}^T\frac{\partial L_t}{\partial U}=\sum_{t=1}^T\sum_{k=1}^t\frac{\partial L_t}{\partial z_k}h_{t-1}^T=\sum_{t=1}^T\sum_{k=1}^t\delta_{t,k}h_{t-1}^T</script><p>P47 7:00</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/deep-learning/" rel="tag"># deep learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/29/test/" rel="prev" title="test">
      <i class="fa fa-chevron-left"></i> test
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/28/%E7%AC%A8%E8%9B%8B%E5%90%AF%E7%A4%BA%E5%BD%95/" rel="next" title="笨蛋启示录">
      笨蛋启示录 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.1.</span> <span class="nav-text">前馈神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83"><span class="nav-number">1.1.1.</span> <span class="nav-text">神经元</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.1.2.</span> <span class="nav-text">神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8C%96"><span class="nav-number">1.1.3.</span> <span class="nav-text">优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.</span> <span class="nav-text">卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.2.1.</span> <span class="nav-text">卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E4%BD%9C%E7%94%A8"><span class="nav-number">1.2.2.</span> <span class="nav-text">卷积作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E6%89%A9%E5%B1%95"><span class="nav-number">1.2.3.</span> <span class="nav-text">卷积扩展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.2.4.</span> <span class="nav-text">二维卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-1"><span class="nav-number">1.2.5.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%92%E7%9B%B8%E5%85%B3"><span class="nav-number">1.2.5.1.</span> <span class="nav-text">互相关</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E4%B8%AA%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="nav-number">1.2.5.2.</span> <span class="nav-text">多个卷积核</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB"><span class="nav-number">1.2.5.3.</span> <span class="nav-text">卷积层的映射关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%88%E6%B1%87%E8%81%9A%E5%B1%82%EF%BC%89"><span class="nav-number">1.2.5.4.</span> <span class="nav-text">池化层（汇聚层）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">1.2.5.5.</span> <span class="nav-text">卷积网络结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.6.</span> <span class="nav-text">其他卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.2.6.1.</span> <span class="nav-text">空洞卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF-%E5%BE%AE%E6%AD%A5%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.2.6.2.</span> <span class="nav-text">转置卷积&#x2F;微步卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C"><span class="nav-number">1.2.6.3.</span> <span class="nav-text">残差网络</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.3.</span> <span class="nav-text">循环神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E5%BB%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.3.1.</span> <span class="nav-text">时延神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%89%E5%A4%96%E9%83%A8%E8%BE%93%E5%85%A5%E7%9A%84%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.2.</span> <span class="nav-text">有外部输入的非线性自回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-1"><span class="nav-number">1.3.3.</span> <span class="nav-text">循环神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E5%BE%AA%E7%8E%AF%E7%BD%91%E7%BB%9C%EF%BC%88SRN%EF%BC%89"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">简单循环网络（SRN）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">参数学习</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yifan Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Clementine24" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Clementine24" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liyif123@126.com" title="E-Mail → mailto:liyif123@126.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yifan Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
